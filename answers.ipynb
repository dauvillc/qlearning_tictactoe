{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58fa93b-5307-40b0-9b87-1896707c25b9",
   "metadata": {},
   "source": [
    "# Mini-project 1: Tic-Tac-Toe\n",
    "Cl√©ment DAUVILLIERS - Florian VINCENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14bd7b-e0ed-415d-a44f-a013a1b5ca3a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": null,
   "id": "b31125c7-3f29-43bb-a467-9caaa336a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "from copy import deepcopy\n",
    "from queue import deque\n",
    "from random import sample\n",
    "from tic_env import TictactoeEnv, OptimalPlayer\n",
    "import numpy.typing as npt\n",
    "from typing import List, Tuple, NewType, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ce705-50db-4f79-9ca4-c1b582865869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "id": "250cc033-1d30-4b7f-9f5b-1314532de708",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "b31125c7-3f29-43bb-a467-9caaa336a99c",
=======
   "execution_count": null,
   "id": "86870d16-c73e-44e9-97fe-ad9346f7c2c9",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid = NewType('Grid', npt.NDArray[np.float64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2b5e6-3607-4252-b997-67dcb8d1646a",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
=======
   "execution_count": null,
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "id": "e20fe206-dcef-43bb-865c-f7d9dfda47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_avg(arr: npt.ArrayLike, window_len: int=250) -> npt.NDArray:\n",
    "    \"\"\"\n",
    "    Computes the average over successive windows of an array.\n",
    "    arr must be a 1D array whose length is a multiple of the\n",
    "    window length.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for win_start in range(0, arr.shape[0], window_len):\n",
    "        result.append(np.mean(arr[win_start:win_start + window_len]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32c475-22d4-4e03-9dac-d32b5adef9eb",
   "metadata": {},
   "source": [
    "## Player class\n",
    "The following class will be used as base for the QLearning and DQN player classes."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": null,
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "id": "46b11f77-858b-4ce3-a796-c5612e69154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    \"\"\"\n",
    "    Base class for both types of players (QLearning, DQN).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 player: str = 'X',\n",
    "                 epsilon: float = 0.05,\n",
    "                 seed: int = 666):\n",
    "\n",
    "        self.player: str = player\n",
    "        self.epsilon: float = epsilon\n",
    "\n",
    "        # RNG for the epsilon-gredy policy\n",
    "        self.rng_ = np.random.default_rng(seed=seed)\n",
    "\n",
    "    def act(self, grid: Grid) -> int:\n",
    "        \"\"\"\n",
    "        Selects an action to perform based on the current\n",
    "        grid state and the player's policy.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Call from abstract class\")\n",
<<<<<<< HEAD
    "        \n",
    "    def set_player(self, player='X', j=-1):\n",
    "        self.player = player\n",
    "        if j != -1:\n",
    "            self.player = 'X' if j % 2 == 0 else 'O'\n",
    "    \n",
=======
    "\n",
    "    def set_player(self, player: str) -> None:\n",
    "        self.player = player\n",
    "\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "    @staticmethod\n",
    "    def empty(grid: Grid) -> List[Tuple[int, int]]:\n",
    "        '''return all empty positions'''\n",
    "        avail = []\n",
    "        for i in range(9):\n",
    "            pos = (int(i/3), i % 3)\n",
    "            if grid[pos] == 0:\n",
    "                avail.append(pos)\n",
    "        return avail\n",
    "\n",
    "    def randomMove(self, grid: Grid) -> Tuple[int, int]:\n",
    "        \"\"\" Chose a random move from the available options. \"\"\"\n",
    "        avail = self.empty(grid)\n",
    "\n",
    "        return avail[self.rng_.integers(0, len(avail))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499d2e6-ceb4-4b41-93b3-f7459700b195",
   "metadata": {},
   "source": [
    "# 2. Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32df3e-82d9-4c5d-8fbe-2b7d7b19ebe0",
   "metadata": {},
   "source": [
    "### QLPlayer class\n",
    "The following class implements the QLearning player."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": null,
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "id": "22d931d5-1c3d-46e8-b6b1-d15ffcbfb2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLPlayer(Player):\n",
    "    \"\"\"\n",
    "    Implements a player that learns using the QLearning algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, player='X',\n",
    "                 lr: float = 0.05,\n",
    "                 discount: float = 0.99,\n",
    "                 epsilon: float = 0.05,\n",
    "                 seed: int = 666):\n",
    "        super().__init__(player, epsilon, seed)\n",
<<<<<<< HEAD
    "        self.lr = lr\n",
    "        self.discount = discount\n",
    "        \n",
=======
    "        self.lr: float = lr\n",
    "        self.discount: float = discount\n",
    "        self.epsilon: float = epsilon\n",
    "\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "        # Q-values grid\n",
    "        # 3^9 = 19683 states and 9 actions\n",
    "        self.qvalues: Grid = np.zeros((19683, 9))\n",
    "\n",
    "        # Memory\n",
    "        self.last_action: Union[None, int] = None\n",
    "        self.last_state: Union[None, Grid] = None\n",
    "\n",
    "    def act(self, grid):\n",
<<<<<<< HEAD
    "        # Remember the state for the next learning step\n",
    "        state = QLPlayer.state_to_int(grid)\n",
    "        self.last_state = state\n",
    "\n",
    "        # Epsilon-greedy choice\n",
    "        if self.rng_.random() < self.epsilon:\n",
    "            chosen_action = self.randomMove(grid)\n",
    "        else:\n",
    "            # Retrieves the list of possible actions and converts them\n",
    "            # from cell positions to integer indexes\n",
    "            avail_actions = QLPlayer.positions_to_ints(Player.empty(grid))\n",
    "            # Ranks ALL actions according to their Qvalues in the current\n",
    "            # state\n",
    "            actions_ranks = np.argsort(self.qvalues[state])[::-1]\n",
    "            # Browses all actions in order of their qvalue rank, until\n",
    "            # finding one that is available\n",
    "            for action in actions_ranks:\n",
    "                if action in avail_actions:\n",
    "                    # Memorizes the action and the current state for the learning\n",
    "                    # phase\n",
    "                    chosen_action = int(action)\n",
    "                    break\n",
    "\n",
    "        # Remember the action for the learning step\n",
    "        self.last_action = chosen_action\n",
    "        return chosen_action\n",
    "    \n",
    "    def learn(self, reward, new_grid, end):\n",
=======
    "        # Inverts the grid if required\n",
    "        grid = self.invert_grid(grid)\n",
    "\n",
    "        # Epsilon-greedy choice\n",
    "        if self.rng_.random() < self.epsilon:\n",
    "            return self.randomMove(grid)\n",
    "        # Retrieves the list of possible actions and converts them\n",
    "        # from cell positions to integer indexes\n",
    "        avail_actions: List[int] = QLPlayer.positions_to_ints(Player.empty(grid))\n",
    "        # Ranks ALL actions according to their Qvalues in the current\n",
    "        # state\n",
    "        state: int = QLPlayer.state_to_int(grid)\n",
    "        actions_ranks: npt.NDArray = np.argsort(self.qvalues[state])[::-1]\n",
    "        # Browses all actions in order of their qvalue rank, until\n",
    "        # finding one that is available\n",
    "        for action in actions_ranks:\n",
    "            if action in avail_actions:\n",
    "                # Memorizes the action and the current state for the learning\n",
    "                # phase\n",
    "                self.last_action, self.last_state = action, state\n",
    "                return int(action)\n",
    "\n",
    "    def learn(self, \n",
    "              reward: int,\n",
    "              new_grid: Grid,\n",
    "              end: int) -> None:\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "        \"\"\"\n",
    "        Updates the Qvalues based on the last (S, A) pair and\n",
    "        the received reward and the new state.\n",
    "        \"\"\"\n",
    "        # If the new_grid is a final state, we can't compute its expected optimal\n",
    "        # qvalue. We instead set it to zero.\n",
    "        if end:\n",
    "            new_state_qval: int = 0\n",
    "        else:\n",
<<<<<<< HEAD
=======
    "            # Inverts the grid if required (so that ones corresponding\n",
    "            # to THIS player's chesses).\n",
    "            new_grid: Grid = self.invert_grid(new_grid)\n",
    "\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "            # Computes the optimal Qvalue in the new state max Q(s', a)\n",
    "            new_state: int = QLPlayer.state_to_int(new_grid)\n",
    "            new_state_qval: np.float64 = np.max(self.qvalues[new_state])\n",
    "\n",
    "        # QValue that needs to be updated Q(s, a)\n",
    "        current_qval: np.float64 = self.qvalues[self.last_state, self.last_action]\n",
    "\n",
    "        self.qvalues[self.last_state, self.last_action] += self.lr * (reward + self.discount * new_state_qval - current_qval)\n",
<<<<<<< HEAD
    "    \n",
=======
    "\n",
    "    def invert_grid(self, grid: Grid) -> Grid:\n",
    "        \"\"\"\n",
    "        Returns a version of the grid in which the ones correspond to this player's\n",
    "        chesses.\n",
    "        \"\"\"\n",
    "        # If we play with the 'O', then the -1 in the grid are actually our pieces\n",
    "        return grid if self.player == 'X' else -grid\n",
    "\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "    @staticmethod\n",
    "    def position_to_int(position: Tuple[int, int]) -> int:\n",
    "        \"\"\"\n",
    "        (row col) -> row*3 + col\n",
    "        \"\"\"\n",
    "        return position[0] * 3 + position[1]\n",
    "\n",
    "    @staticmethod\n",
    "    def positions_to_ints(positions: List[Tuple[int, int]]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Given a list of cells [(a, b), (c, d), ..],\n",
    "        returns the list of the corresponding indexes.\n",
    "        \"\"\"\n",
    "        return [QLPlayer.position_to_int(cell) for cell in positions]\n",
    "\n",
    "    @staticmethod\n",
    "    def state_to_int(grid: Grid) -> int:\n",
    "        \"\"\"\n",
    "        Converts a grid state to the index of its\n",
    "        row in the lookup table.\n",
    "        \"\"\"\n",
    "        # Converts the grid values from -1, 0, 1 to 0, 1, 2 (a base 3 number)\n",
    "        # Then converts the base 3 number to base 10\n",
    "        return int((np.ravel(grid) + 1) @ np.array([3 ** i for i in range(9)]))\n",
    "\n",
    "    @staticmethod\n",
    "    def int_to_state(state_int: int) -> Grid:\n",
    "        \"\"\"\n",
    "        Converts the index of row in the qvalues table to\n",
    "        its corresponding state.\n",
    "        \"\"\"\n",
    "        # Converts from base 10 to base 3\n",
    "        return np.array([\n",
    "            (state_int % (3 ** (i + 1))) // (3 ** i)\n",
    "            for i in range(9)\n",
    "        ]).reshape((3, 3)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b2b39-d3e1-4de5-abf7-6fd73cd57acf",
   "metadata": {},
   "source": [
    "## 2.1 Learning from experts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96654ae4-a652-4435-945b-5a82a533c250",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 38,
=======
   "execution_count": null,
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "id": "1ea95936-f056-43f1-93af-1072a940bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_games(learning_player: Union[Player, OptimalPlayer],\n",
    "               benchmark_player: Union[Player, OptimalPlayer],\n",
    "               nb_games: int = 20000,\n",
    "               turns_swap: str = \"switch\",\n",
    "               seed: int = 666,\n",
    "               learn: bool = True) -> npt.NDArray[np.int_]:\n",
    "    \"\"\"\n",
    "    Plays a given number of games between two players, and returns the rewards.\n",
    "    --learning_player: Player object implementing act(), learn(), update();\n",
    "    --benchmark_player: Player object implementing act();\n",
    "    --nb_games: How many games should be played;\n",
    "    --turns_swap: str, either \"switch\" to switch turns after every game, or \"random\".\n",
    "    --seed: random seed.\n",
    "    \"\"\"\n",
<<<<<<< HEAD
    "    turns = np.array(['X', 'O'])\n",
=======
    "    turns: npt.NDArray[np.string_] = np.array(['X', 'O'])\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "    learning_player.set_player(turns[0])\n",
    "    benchmark_player.set_player(turns[1])\n",
    "    rewards: List[int] = []\n",
    "    env = TictactoeEnv()\n",
    "\n",
    "    for game in trange(nb_games):\n",
    "        # Sets up the environment for the game\n",
    "        env.reset()\n",
    "        grid: Grid = env.observe()[0]\n",
    "        if turns_swap == \"switch\":\n",
    "            learning_player.set_player(j=game)\n",
    "            benchmark_player.set_player(j=game + 1)\n",
    "        else:\n",
    "            turns = np.random.shuffle(turns)\n",
<<<<<<< HEAD
    "            learning_player.set_player(turns[0])\n",
    "            benchmark_player.set_player(turns[1])\n",
    "        \n",
=======
    "        learning_player.set_player(turns[0])\n",
    "        benchmark_player.set_player(turns[1])\n",
    "\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "        while True:\n",
    "            # Action step\n",
    "            if env.current_player == learning_player.player:\n",
    "                move: int = learning_player.act(grid)\n",
    "            else:\n",
    "                move: int = benchmark_player.act(grid)\n",
    "\n",
    "            grid, end, winner = env.step(move, print_grid=False)\n",
    "            reward: int = env.reward(learning_player.player)\n",
    "\n",
    "            # Learning step\n",
    "            # The agent learns only after the other has played, as from the\n",
    "            # point of view of the agent, the next state is not the one right after\n",
    "            # its move, but the next state in which the agent will need to make a decision.\n",
    "            # if current player == learning player means the benchmark player just played !\n",
    "            if (env.current_player == learning_player.player or end) and learn:\n",
    "                learning_player.learn(reward, grid, end)\n",
    "\n",
    "            if end:\n",
    "                rewards.append(reward)\n",
    "                break\n",
    "\n",
    "    return np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 72,
   "id": "cc53ea42-3aad-44b6-abd6-55e7aab286ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b856eecd2ba4d158f717797d4550c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "e865c195-e3d9-4a6a-9603-c233a9471915",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlplayer = QLPlayer(epsilon=0.1)\n",
    "semi_random_player = OptimalPlayer(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53ea42-3aad-44b6-abd6-55e7aab286ec",
   "metadata": {},
   "outputs": [],
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "source": [
    "nb_games = 20000\n",
    "qlplayer = QLPlayer(epsilon=0.01)\n",
    "semi_random_player = OptimalPlayer(0.5)\n",
    "rewards_21 = play_games(qlplayer, semi_random_player, nb_games=nb_games)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 73,
   "id": "0a3a7434-9f97-4867-8cfc-ca93c850d876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "id": "0a3a7434-9f97-4867-8cfc-ca93c850d876",
   "metadata": {},
   "outputs": [],
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "source": [
    "window_size = 250\n",
    "plt.plot(windowed_avg(rewards_21, window_size))\n",
    "plt.ylabel('Average final reward over 250 games')\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel('Games played')\n",
    "xticks = np.arange(nb_games // window_size + 1, step=10)\n",
    "plt.xticks(xticks, xticks * window_size)\n",
    "plt.suptitle(\"QLearning vs Optimal(0.5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5242a9-7f44-4147-80de-4bd8ca20a9a0",
   "metadata": {},
   "source": [
    "# 3. Deep Q-Learning\n",
    "All of the following implementations will be based on the PyTorch RL Tutorial:  \n",
    "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.htmlhttps://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76ce705-50db-4f79-9ca4-c1b582865869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple"
   ]
  },
  {
=======
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
   "cell_type": "markdown",
   "id": "79746898-a689-4fd0-abee-6c7897c628cf",
   "metadata": {},
   "source": [
    "We'll try to work on a GPU if one is available to PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff27fc3e-b8aa-4a4c-b391-7ebecf264f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315c8eb-2938-48a3-8959-507049afcd7c",
   "metadata": {},
   "source": [
    "## Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0f38b6-dda0-4e27-ae44-498ac117aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"\n",
    "    state (3,3,2)->flatten->(18,) nn input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.input = nn.Linear(18, 128)\n",
    "        self.hidden1 = nn.Linear(128, 128)\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        self.output = nn.Linear(128, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        # Flattens x to make sure it can be passed to the linear layers\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        # No activation is a linear activation\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2681db-9713-440a-bbea-73a865d205d9",
   "metadata": {},
   "source": [
    "## Replay memory\n",
    "This class is directly taken from the PyTorch DQN tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9bf7201-8a61-456b-a638-eff02c09e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455aa26-ee1a-4d0b-b329-284c6b75278f",
   "metadata": {},
   "source": [
    "## DQNPlayer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f19284-361f-400f-9f62-66dedd5e9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNPlayer(Player):\n",
    "    \"\"\"\n",
    "    Implements a type of Player that uses Deep Q-Learning\n",
    "    to learn the tictactoe strategy.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, player='X', lr=5e-4, discount=0.99, epsilon=0.05, batch_size=64,\n",
    "                  seed=666):\n",
    "        super().__init__(player, epsilon, seed)\n",
    "        self.lr = lr\n",
    "        self.discount = discount\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.last_action, self.last_state = None, None\n",
    "\n",
    "        # Neural networks\n",
    "        self.policy_net = DQN().to(device)\n",
    "        self.target_net = DQN().to(device)\n",
    "\n",
    "        self.memory = ReplayMemory(10000)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Huber loss\n",
    "        self.criterion = nn.HuberLoss()\n",
    "        # Adam optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.policy_net.parameters(),\n",
    "                                          lr=self.lr)\n",
    "\n",
    "    def learn(self, reward, grid):\n",
    "        \"\"\"\n",
    "        Stores the last (S, A, NS, R) tuple into the replay memory,\n",
    "        and trains the policy network using a sample from the replay memory.\n",
    "        --reward: float, end game reward\n",
    "        --grid: (3, 3, 2) array representing the current state.\n",
    "        Returns the value of the Huber loss.\n",
    "        \"\"\"\n",
    "        # Push the last experience into the replay memory\n",
    "        self.memory.push(self.last_state, self.last_action, grid, reward)\n",
    "\n",
    "        # We don't start learning before the replay memory is large enough to\n",
    "        # return at least a full batch\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        # ## Policy network training ==========================================\n",
    "        # Taken from the Pytorch RL tutorial\n",
    "        # First sample a batch of Transition objects\n",
    "        transitions = self.memory.sample(self.batch_size)\n",
    "        # Then creates a single Transition obj whose elements are arrays\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        next_state_batch = torch.cat(batch.next_state)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        # We need to know where in the batch the next state is final\n",
    "        # as we can't compute max Q(ns, .) for those.\n",
    "        # The final states are characterized by having the sum of the grid\n",
    "        # equal to 9 (1 for each cell).\n",
    "        non_final_mask = next_state_batch.sum((1, 2, 3)) < 9\n",
    "        non_final_next_states = next_state_batch[non_final_mask]\n",
    "\n",
    "        # Computes the state-action values for all actions for all states in\n",
    "        # the batch\n",
    "        state_action_values = self.policy_net(state_batch)\n",
    "        # For each state, selects only Q(s, a) for the a which was\n",
    "        # actually chosen\n",
    "        state_action_values = state_action_values.gather(1, action_batch)\n",
    "\n",
    "        # We now need to compute max_a Q(s', a)\n",
    "        next_state_qvalues = torch.zeros(self.batch_size, device=device)\n",
    "        # We'll set it to zero for final states\n",
    "        # Make sure to use the target network (not the policy) for\n",
    "        # training stability.\n",
    "        # Note that tensor.max(dim=...) returns a namedtuple (values, indices)\n",
    "        next_state_qvalues[non_final_mask] =\\\n",
    "            self.target_net(non_final_next_states).max(dim=1).values\n",
    "        # Detach the next state values from the gradient graph as it will be\n",
    "        # used as the target in the computation of the loss (We consider it as\n",
    "        # the \"true qvalue\" and hope to converge towards the Bellman equation).\n",
    "        next_state_qvalues = next_state_qvalues.detach()\n",
    "\n",
    "        # Final objective term\n",
    "        target = reward_batch + self.discount * next_state_qvalues\n",
    "\n",
    "        # Loss minimization using the optimizer (usual PyTorch training phase)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion(state_action_values, target.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        # Returns the loss as a float value\n",
    "        return loss.item()\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Udpates the target network by setting its weights\n",
    "        to those of the policy network.\n",
    "        \"\"\"\n",
    "        # We need to make a copy of the policy net's state_dict,\n",
    "        # otherwise we'll keep updating the target net at each iteration\n",
    "        state_dict = self.policy_net.state_dict()\n",
    "        # Calling deepcopy() seems to be the \"best\" way:\n",
    "        # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        self.target_net.load_state_dict(deepcopy(state_dict))\n",
    "\n",
    "    def act(self, grid):\n",
    "        \"\"\"\n",
    "        Chooses the action to perform by taking that which returns the\n",
    "        best qvalue, as estimated by the policy network.\n",
    "        Returns the action taken as an integer from 0 to 8.\n",
    "        \"\"\"\n",
    "        # Check whether the epsilon-greedy choice activates\n",
    "        if self.rng_.random() < self.epsilon:\n",
    "            action = torch.tensor([[self.rng_.integers(0, 9)]], device=device)\n",
    "        else:\n",
    "            # We don't want those computations to impact the gradient graph\n",
    "            # somehow\n",
    "            with torch.no_grad():\n",
    "                qvalues = self.policy_net(grid)\n",
    "                # Select the action that has the highest qvalue\n",
    "                # Note that tensor.max(dim=...) returns a namedtuple (values, indices)\n",
    "                action = qvalues.max(dim=1).indices[0]\n",
    "                # The action must have shape (1, 1) so that they can be concatenated\n",
    "                # when sampled from the replay memory\n",
    "                action = action.view(1, 1)\n",
    "\n",
    "        self.last_state = grid\n",
    "        self.last_action = action\n",
    "        return int(action.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b286b8-cf7f-48f8-8b23-ee1d7528f12c",
   "metadata": {},
   "source": [
    "## Game function for DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb1de97-16f4-4347-9ffe-5bbf9b406105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid33_to_332(grid, player, player2value):\n",
    "    \"\"\"\n",
    "    Converts a grid in 3x3 shape whose values are -1, 0 and 1\n",
    "    to the format expected by the DQN player, as a 3x3x2 array.\n",
    "    --player: either 'X' or 'O', which player the DQN agent is.\n",
    "    --player2value: player (X or O) to index (-1 or 1) association,\n",
    "        obtained from the environment.\n",
    "    \"\"\"\n",
    "    grid_332 = np.zeros((3, 3, 2))\n",
    "    # Get the value in the original grid corresponding to the player\n",
    "    # played by the dqn agent:\n",
    "    player_ind = player2value[player]\n",
    "\n",
    "    grid_332[grid == player_ind, 0] = 1\n",
    "    grid_332[grid == -player_ind, 1] = 1\n",
    "    return grid_332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0e81180-76b9-4494-a691-5018fe6f479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_games_dqn(dqn_player, benchmark_player, nb_games=20000,\n",
    "                   games_between_updates=500,\n",
    "                   turns_swap=\"switch\",\n",
    "                   seed=666):\n",
    "    \"\"\"\n",
    "    Plays a given number of games between two players, and returns the rewards.\n",
    "    --dqn_player: Instance of DQNPlayer to train;\n",
    "    --benchmark_player: Player object implementing act();\n",
    "    --nb_games: How many games should be played;\n",
    "    --games_between_updates: how many games are played between two updates of the agent's\n",
    "        target network.\n",
    "    --turns_swap: str, either \"switch\" to switch turns after every game, or \"random\".\n",
    "    --seed: random seed.\n",
    "    Returns two arrays: rewards, losses\n",
    "    \"\"\"\n",
    "    turns = np.array(['X','O'])\n",
    "    dqn_player.set_player(turns[0])\n",
    "    benchmark_player.set_player(turns[1])\n",
    "    rewards, losses = [], []\n",
    "    env = TictactoeEnv()\n",
    "\n",
    "    for game in trange(nb_games):\n",
    "        # Sets up the environment for the game\n",
    "        env.reset()\n",
    "        grid, _, _ = env.observe()\n",
<<<<<<< HEAD
    "        \n",
=======
    "        # Convert the grid from the env's format to that expected by the agent\n",
    "        grid_tensor = grid33_to_332(grid, dqn_player.player, env.player2value)\n",
    "        grid_tensor = torch.tensor(grid_tensor, device=device).unsqueeze(0).float()\n",
    "\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "        if turns_swap == \"switch\":\n",
    "            turns = turns[[-1, 0]]\n",
    "        else:\n",
    "            turns = np.random.shuffle(turns)\n",
    "\n",
    "        dqn_player.set_player(turns[0])\n",
    "        benchmark_player.set_player(turns[1])\n",
<<<<<<< HEAD
    "        # Convert the grid from the env's format to that expected by the agent\n",
    "        grid_tensor = grid33_to_332(grid, dqn_player.player, env.player2value)\n",
    "        grid_tensor = torch.tensor(grid_tensor, device=device).unsqueeze(0).float()\n",
    "        \n",
=======
    "\n",
>>>>>>> 68f169a26e57d1c18f8efd3e8c9cc18a4be149ff
    "        while True:\n",
    "            # Action step\n",
    "            # We now need to account for the case where the agent chooses\n",
    "            # an unavailable position.\n",
    "            if env.current_player == dqn_player.player:\n",
    "                try:\n",
    "                    move = dqn_player.act(grid_tensor)\n",
    "                    grid, end, winner = env.step(move, print_grid=False)\n",
    "\n",
    "                except ValueError:\n",
    "                    # Stop the game and set the reward for the agent to -1\n",
    "                    end = True\n",
    "                    reward = -1\n",
    "            else:\n",
    "                move = benchmark_player.act(grid)\n",
    "                grid, end, winner = env.step(move, print_grid=False)\n",
    "                grid_tensor = grid33_to_332(grid, dqn_player.player, env.player2value)\n",
    "                grid_tensor = torch.tensor(grid_tensor, device=device).unsqueeze(0).float()\n",
    "                reward = env.reward(dqn_player.player)\n",
    "\n",
    "                # Learning step\n",
    "                # The DQN agent must have played at least once to start learning\n",
    "                if env.current_player == benchmark_player.player or end:\n",
    "                    losses.append(dqn_player.learn(torch.tensor([reward], device=device),\n",
    "                                                   grid_tensor))\n",
    "\n",
    "            if end:\n",
    "                env.reset()\n",
    "                rewards.append(reward)\n",
    "                break\n",
    "\n",
    "        # Update the agent's target network if required\n",
    "        if game % games_between_updates == 0:\n",
    "            dqn_player.update()\n",
    "\n",
    "    return np.array(rewards), np.array(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230333e9-692a-45bc-8112-4a0bc2e413d1",
   "metadata": {},
   "source": [
    "### 3.2 Learning from experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba9d785c-faf2-48f2-8e28-a67f6a77c653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168e23ed10d741489797ec909e9103ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "semi_opt_player = OptimalPlayer(0.5)\n",
    "dqn_player = DQNPlayer(epsilon=0.05)\n",
    "rewards, losses = play_games_dqn(dqn_player, semi_opt_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cd55d4f-975b-4653-9f4e-fff8929cb5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(windowed_avg(rewards))\n",
    "plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52247300-b635-4262-a8df-b703aad442e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
